# automation-chronichles
libraries for [automation chronicles sieries on my Substack](https://thepoorgpuguy.substack.com/t/automation-chronicles)

the python file AMlib.py contains all helper functions for:
- OpenAI-compatible API (via llama.cpp server at localhost:8080)
- Pydantic for structured output (keywords with relevance scores, table of contents)
- Plain chat completions for human-readable summarization
- Markdown-to-HTML email sending via Gmail (or other SMTP)

The workflow is:
- User pastes a long article
- Local LLM extracts:
  - Structured keywords
  - Table of contents
  - Narrative summary with key points and author stance

Results are formatted and emailed


## Install required Python packages
   ```bash
   pip install tkinter openai pydantic markdown
   ```

---

# ğŸ§  Article Analyzer + Emailer (Local LLM Edition)

A lightweight Python tool that uses your **local LLM** (via `llama.cpp` server) to read long articles and automatically generate:

- âœ¨ A clear, jargon-free **summary**
- ğŸ“š A structured **Table of Contents**
- ğŸ”‘ **Key topics** with relevance scores
- ğŸ“© All delivered neatly via **email**

Built for privacy-conscious users who want AI-powered analysis **without sending data to the cloud**.

---

## ğŸš€ Features

- **100% local processing**: Works with any LLM served via [llama.cpp](https://github.com/ggerganov/llama.cpp) with OpenAI-compatible API (e.g., at `http://localhost:8080/v1`)
- **Structured outputs**: Uses Pydantic + OpenAIâ€™s `response_format` for reliable, parseable results
- **Human-readable summaries**: Focuses on plain language, key insights, and author perspective
- **Email delivery**: Sends beautifully formatted HTML emails (Markdown â†’ HTML) via Gmail or any SMTP provider
- **Easy input**: Paste full articles directly into the terminal (Ctrl+D of Ctrl+Z to submit)

---

## ğŸ› ï¸ Requirements

- Python 3.9+
- A local LLM running with an **OpenAI-compatible API** (e.g., `llama.cpp` server on `localhost:8080`)
- The following Python packages:

```bash
pip install openai pydantic markdown
```

> ğŸ’¡ **Note**: Your LLM server must support `/v1/chat/completions` and (for structured output) the `response_format` parameter.

---

## ğŸ“¦ Setup for CLI only app

1. **Start your local LLM server**  
   Example with `llama.cpp`:
   ```bash
   ./llama-server.exe -m your-model.gguf --port 8080
   ```
   Ensure itâ€™s accessible at `http://localhost:8080/v1`.

2. **Download AClib.py**  
   ```bash
   from this repo
   ```

3. **Install dependencies**  
   ```bash
   pip install openai pydantic markdown
   ```

4. **Follow the articles with tutorial in my Substack**  
   - [The PoorGPUguy  Automation Chronicles](https://thepoorgpuguy.substack.com/t/automation-chronicles) 
   
---

## â–¶ï¸ Usage

Run the script:

```bash
python analyze_article.py
```

1. **Paste your article** when prompted (use **Ctrl+D** on Linux/macOS or **Ctrl+Z + Enter** on Windows to finish)
2. The local LLM will:
   - Read the full text
   - Generate summary, TOC, and keywords
3. **Enter your email credentials** when asked
4. Receive a beautifully formatted email with all insights!

> ğŸ” All processing happens on your machineâ€”your article never leaves localhost.

---

## ğŸ“§ Email Example

The email includes:

- **Summary**: Plain-English overview + 3 key points + author stance  
- **Table of Contents**: Logical section breakdown  
- **Top Keywords**: 5 core concepts with relevance scores (0.0â€“1.0) and explanations  

Formatted in clean HTML with Markdown styling!

---

## âš™ï¸ Customization

- **Model name**: Set `MODEL_NAME` in the script (default: `"localai"`)
- **LLM server URL**: Hardcoded to `http://localhost:8080/v1`â€”adjust the `OpenAI` client base URL if needed:
  ```python
  client = OpenAI(base_url="http://localhost:8080/v1", api_key="sk-no-key-needed")
  ```
- **Email provider**: Change `smtp_server` and `smtp_port` in `send_markdown_email()` for Outlook, Yahoo, etc.

---

## ğŸ›¡ï¸ Privacy & Security

- No data is sent to external servers
- Email credentials are only used during runtime (not stored)
- Runs entirely offline once your LLM server is up

---

## ğŸ™Œ Inspired By

- [llama.cpp](https://github.com/ggerganov/llama.cpp) â€“ for making local LLMs accessible
- OpenAIâ€™s structured output API â€“ for reliable parsing
- Markdown â€“ for clean, readable output formatting

---

## ğŸ“ License

MIT License â€“ feel free to use, modify, and share!

---

> ğŸ’¡ **Tip**: Pair this with a fast 1.2B quantized model (e.g., `LFM2-1.2b`, `qwen3-4b-instruct`) for best speed/quality balance on consumer hardware.



---


# ğŸ“˜ Tutorial: Building a Desktop Article Analyzer App with Python & Local AI
#### The entire tkinter GUI app

---

## ğŸ¯ What This App Does

This tutorial explains a **desktop application** built with Python that helps you:

- **Paste a long article or text**
- **Automatically analyze it using a local AI model** (no internet needed!)
- Get back:
  - A clear **summary**
  - A structured **Table of Contents**
  - The **top 5 keywords** with explanations
- **Email the full report** to yourself (or anyone)
- **Open a nicely formatted report** on your computer

All processing happens on **your own machine**, using a local AI server (like `llama.cpp`). Your data never leaves your computer!

---

## ğŸ§© How Itâ€™s Built: Two Main Files

Your project has two Python files:

1. **`AClib.py`** â†’ Contains all the "smart" functions (AI analysis, email sending, etc.)
2. **`gui_app.py`** â†’ The visual app window you interact with (built with **Tkinter**)

> âœ… **You already understand `AClib.py`** â€“ so this tutorial focuses on **how the GUI (`gui_app.py`) works** and **how to use it**.

---

## ğŸ–¥ï¸ Part 1: Understanding the GUI App (`gui_app.py`)

### ğŸ”§ Setup & Configuration

At the top of `gui_app.py`, youâ€™ll see some settings:

```python
SENDER_EMAIL = "youemail@gmail.com"
SENDER_PASSWORD = "abcd efgh ijkl mnop"  # Gmail App Password!
RECEIVER_EMAIL = "someoneelse@email.com"
```

> â— **Important**:  
> - Use a **Gmail App Password** (not your regular password).  
> - Enable 2FA in Gmail, then generate a 16-digit app password [here](https://myaccount.google.com/apppasswords).

It also connects to your **local AI server**:

```python
client = OpenAI(
    base_url="http://localhost:8080/v1",
    api_key="not-needed"
)
```

> ğŸ’¡ This assumes youâ€™re running a local LLM server (like `llama.cpp` with OpenAI-compatible API) on port `8080`.  
> If you use a different port, change `8080` accordingly.

---

### ğŸªŸ The Window Layout

The app window has:

1. **Input box** â€“ Where you paste your article text  
   (big scrollable area)
2. **Two buttons**:
   - **"Analyze & Email Report"** â†’ Starts the magic!
   - **"Quit"** â†’ Closes the app
3. **Progress bar** â€“ Shows how far along the analysis is
4. **Timer** â€“ Counts how long the analysis takes
5. **Status message** â€“ Tells you whatâ€™s happening (e.g., â€œGenerating summaryâ€¦â€)

All this is built using **Tkinter**, Pythonâ€™s built-in GUI toolkit.

---

### â–¶ï¸ What Happens When You Click â€œAnalyzeâ€?

1. **Checks if text is pasted**  
   â†’ If empty, shows a warning.

2. **Locks the button**  
   â†’ Prevents double-clicking.

3. **Starts a background process** (using `threading`)  
   â†’ Keeps the app responsive while AI works (which can take time!).

4. **Runs 4 steps in order**:
   - **Step 1**: Ask AI to read & summarize the article
   - **Step 2**: Extract a clean Table of Contents
   - **Step 3**: Pull out 5 key keywords with relevance scores
   - **Step 4**: Format everything into a report â†’ **email it** â†’ **save & open locally**

5. **Updates progress** in real-time  
   â†’ You see exactly what the AI is doing.

6. **When done**:  
   - Opens the report in your default browser/text editor  
   - Shows â€œâœ… Report sent by email & opened locally!â€

---

### ğŸ“¤ How the Report Looks

The final report is a **Markdown (.md) file** â€“ clean and readable:

```markdown
# ğŸ“Š Article Analysis Report

## ğŸ“ Summary
[Short plain-English summary here]

## ğŸ—‚ï¸ Table of Contents
- **Introduction**
  â†’ Explains the problem being addressed...
- **Methodology**
  â†’ Describes the experimental setup...

## ğŸ”‘ Keywords
1. **Quantum decoherence** (0.92)
   â†’ Central to the paper's argument about stability...
2. **Topological qubits** (0.87)
   â†’ Proposed as a solution to error rates...
...
```

This gets **emailed to you** and **saved temporarily** on your computer.

---

## ğŸ› ï¸ How to Use This App (Step-by-Step)

### âœ… Prerequisites

1. **Run a local LLM server**  
   Example using `llama.cpp` with OpenAI API support:
   ```bash
   ./server -m models/your-model.gguf --port 8080
   ```
   (Make sure itâ€™s running before starting the app!)

2. **Set up Gmail App Password**  
   - Go to [Google App Passwords](https://myaccount.google.com/apppasswords)
   - Create one for â€œMailâ€ â†’ copy the 16-digit code

3. **Install required Python packages**:
   ```bash
   pip install tkinter openai pydantic markdown
   ```

### â–¶ï¸ Running the App

1. Open terminal
2. Navigate to your project folder
3. Run:
   ```bash
   python gui_app.py
   ```
4. A window pops up â†’ **paste your article**
5. Click **â€œAnalyze & Email Reportâ€**
6. Wait 10â€“60 seconds (depends on article length & your PC)
7. Check your email + a report opens on your screen!

---

## ğŸ”’ Privacy & Safety

- âœ… **No data leaves your computer** â€“ AI runs locally
- âœ… **Email only sends the final report** (not your raw input)
- âŒ Never put sensitive/personal info in the article if youâ€™re unsure

---

## ğŸ› ï¸ Customization Tips

### Change who receives the email:
```python
RECEIVER_EMAIL = "your-email@example.com"
```

### Use a different email provider (e.g., Outlook):
```python
SMTP_SERVER = "smtp-mail.outlook.com"
SMTP_PORT = 587  # Note: may need STARTTLS
```
> âš ï¸ Youâ€™ll need to adjust the `send_markdown_email` function for non-Gmail servers.

### Disable email & just save locally:
Comment out the email line in `run_analysis()`:
```python
# send_markdown_email(...)  # â† comment this
```

---

## â“ Common Issues & Fixes

| Problem | Solution |
|-------|--------|
| **â€œConnection refusedâ€** | Make sure your LLM server is running on `localhost:8080` |
| **Email fails** | Double-check app password & Gmail settings |
| **App freezes** | Wait! Large articles take time. Progress bar shows itâ€™s working. |
| **No report opens** | Check the error message â€“ file is still saved (path shown) |

---

## ğŸŒŸ Final Thoughts

This app turns your **local AI model** into a **personal research assistant**!  
You can analyze news articles, research papers, meeting notes â€“ all **offline and private**.

And because itâ€™s open-source and built with standard Python tools, you can **modify it** to:
- Add PDF/text file upload
- Save reports to a folder
- Add more AI analysis types (sentiment, entities, etc.)

---

## ğŸ“ Bonus: Want to Try Without Coding?

You can share this app with friends! Just:
1. Package it with `pyinstaller`
2. Give them the executable + instructions to run their own local LLM

> ğŸŒ Local AI is the future of private, fast, and free text analysis!

---

**Happy analyzing!** ğŸš€  
*Built with â¤ï¸ using Python, Tkinter, and your own AI brain.*


# ğŸ“˜ Understanding the Tkinter App: Python Explained Simply

**A gentle walkthrough of `gui_app.py` â€“ no coding expertise needed!**

Think of this app like a friendly robot assistant that lives on your desktop. You talk to it through buttons and text boxes, and it uses AI to analyze your articles. Below, weâ€™ll peek â€œunder the hoodâ€ to see how each part worksâ€”using plain language and helpful analogies.

---

## ğŸ—ï¸ 1. Setting Things Up: Imports & Configuration

```python
import tkinter as tk
from tkinter import scrolledtext, messagebox, ttk
import threading
import os
import webbrowser
import tempfile
from datetime import datetime
import time

from AClib import (
    genSummary,
    generate_toc,
    extract_keywords,
    send_markdown_email
)
from openai import OpenAI
```

### Whatâ€™s happening?
- **`tkinter`**: This is Pythonâ€™s built-in toolbox for making windows, buttons, and text boxes.  
  â†’ `tk` is the main module.  
  â†’ `scrolledtext` gives you a text box with a scroll bar (perfect for long articles!).  
  â†’ `messagebox` shows pop-up alerts (like â€œOops! You forgot to paste text.â€).  
  â†’ `ttk` adds modern-looking widgets (like the sleek progress bar).

- **`threading`**: Lets the app do two things at once!  
  â†’ While the AI is thinking (which takes time), your app *doesnâ€™t freeze*.  
  â†’ Like ordering coffee while still browsing the menu.

- **`tempfile` & `webbrowser`**: Used to **save your report temporarily** and **open it in your browser**â€”like auto-opening a PDF after download.

- **`from AClib import ...`**: This is where your app borrows the â€œsmartâ€ functions you already built!  
  â†’ Itâ€™s like hiring a team of experts (summary writer, keyword finder, email sender) just by saying their names.

---

## ğŸŒ 2. Connecting to Your Local AI

```python
client = OpenAI(
    base_url="http://localhost:8080/v1",
    api_key="not-needed"
)
```

### Whatâ€™s happening?
This tells your app:  
> â€œHey! The AI brain is running right here on my computer, at `localhost:8080`.â€

- **`localhost`** = your own computer.  
- **`8080`** = the â€œdoor numberâ€ (port) where your AI server is listening.  
- **`api_key="not-needed"`** = since itâ€™s local, no password is required (unlike cloud APIs).

ğŸ’¡ If you change the port in your `llama.cpp` server, update this number too!

---

## ğŸ¨ 3. Building the Window: `__init__` Method

```python
class ArticleAnalyzerGUI:
    def __init__(self, root):
        self.root = root
        root.title("ğŸ“ Article Analyzer (Local LLM)")
        root.geometry("850x600")
        ...
```

### Whatâ€™s happening?
This is the **blueprint for your app window**.

- **`class ArticleAnalyzerGUI`**: A â€œrecipeâ€ for creating the app. Every time you run it, it follows this recipe.
- **`self.root = root`**: `root` is the main window. We save it so we can change it later (like updating buttons).
- **`root.title(...)`**: Sets the window name (what you see at the top).
- **`root.geometry(...)`**: Sets the window sizeâ€”850 pixels wide, 600 tall.

Then, it adds:
- A **label** (â€œPaste your article text belowâ€)
- A **big text box** (`scrolledtext.ScrolledText`) where you paste your article
- **Buttons** (â€œAnalyzeâ€ and â€œQuitâ€) in a row (`btn_frame`)
- A **progress bar** (shows how much is done)
- A **timer** (â€œElapsed: 5.2sâ€)
- A **status message** (â€œGenerating summaryâ€¦â€)

All these pieces are **â€œpackedâ€** into the windowâ€”like placing furniture in a room.

---

## â–¶ï¸ 4. Starting the Analysis: `start_analysis()` Method

```python
def start_analysis(self):
    article = self.input_text.get("1.0", tk.END).strip()
    if not article:
        messagebox.showwarning("Empty Input", "Please paste an article first.")
        return
    ...
```

### Whatâ€™s happening?
This runs **when you click â€œAnalyzeâ€**.

- **`self.input_text.get("1.0", tk.END)`**: Grabs all text from the input box.  
  â†’ `"1.0"` means â€œstart at line 1, character 0â€.  
  â†’ `tk.END` means â€œgo to the very endâ€.
- **`.strip()`**: Removes extra blank spaces at the start/end.
- If the article is empty â†’ show a warning and **stop**.

Then:
- It **resets the progress bar and timer**
- **Disables the button** (so you canâ€™t click it twice)
- **Starts a timer** (`update_timer()`)
- **Launches the analysis in the background** using `threading.Thread(...)`

> ğŸ§µ **Why threading?**  
> Without it, the whole app would freeze while waiting for AI. With threading, the window stays responsiveâ€”you can even move it around!

---

## â±ï¸ 5. Keeping Time: `update_timer()` Method

```python
def update_timer(self):
    if self.analysis_active:
        elapsed = time.time() - self.analysis_start_time
        self.time_var.set(f"Elapsed: {elapsed:.1f}s")
        self.root.after(100, self.update_timer)
```

### Whatâ€™s happening?
This is a **mini clock** that ticks every 0.1 seconds.

- **`self.root.after(100, ...)`**: â€œIn 100 milliseconds, run this function again.â€  
  â†’ This creates a smooth, updating timerâ€”like a stopwatch!
- **`self.time_var.set(...)`**: Updates the text you see (â€œElapsed: 3.4sâ€)

It only runs while analysis is active (`self.analysis_active = True`).

---

## ğŸ”„ 6. Showing Progress: `update_status_and_progress()`

```python
def update_status_and_progress(self, step, total_steps, message):
    self.progress['value'] = (step / total_steps) * 100
    self.status_var.set(message)
    self.root.update_idletasks()
```

### Whatâ€™s happening?
This **refreshes the progress bar and status message** during analysis.

- **`self.progress['value'] = ...`**: Fills the bar (e.g., 2/4 steps â†’ 50% full)
- **`self.status_var.set(...)`**: Changes the big bold message (â€œStep 2/4: Generating Table of Contentsâ€¦â€)
- **`self.root.update_idletasks()`**: Forces the window to **redraw immediately**  
  â†’ Without this, youâ€™d only see updates *after* the whole analysis finishes!

---

## ğŸ¤– 7. The Brain: `run_analysis()` Method

```python
def run_analysis(self, article):
    total_steps = 4
    try:
        final_markdown = "# ğŸ“Š Article Analysis Report\n\n"

        # â¤ STEP 1: Summary
        self.update_status_and_progress(1, total_steps, "Step 1/4: Generating summary...")
        summary = genSummary(client, article)
        final_markdown += f"## ğŸ“ Summary\n\n{summary}\n\n"
        ...
```

### Whatâ€™s happening?
This is the **core workflow**â€”the appâ€™s â€œto-do listâ€:

1. **Start with a report title** (`# ğŸ“Š Article Analysis Report`)
2. **Step 1**: Call `genSummary()` â†’ add result to report
3. **Step 2**: Call `generate_toc()` â†’ format as bullet points
4. **Step 3**: Call `extract_keywords()` â†’ list with relevance scores
5. **Step 4**:  
   - **Email the report** using `send_markdown_email()`  
   - **Save it locally** using `tempfile.NamedTemporaryFile()`  
     â†’ Creates a real `.md` file on your computer (e.g., `/tmp/tmp12345.md`)

> ğŸ“ **Why `tempfile`?**  
> It automatically picks a safe, unique filename so you donâ€™t overwrite old reports.

All of this runs in the **background thread**, so your window stays smooth.

---

## ğŸ‰ 8. Wrapping Up: `show_completion()` & `reset_ui()`

```python
def show_completion(self, md_path):
    self.reset_ui()
    ...
    webbrowser.open(f"file://{md_path}")
```

### Whatâ€™s happening?
When analysis finishes:

- **`reset_ui()`**: Re-enables the button, resets status â†’ app is ready again!
- **`webbrowser.open(...)`**: Opens the report in your default browser  
  â†’ On Windows, `os.startfile()` does the same (opens in default app)

If opening fails (rare), it shows a warning with the file pathâ€”so you can find it manually.

---

## ğŸ§  Key Concept Recap

| Concept | Why It Matters |
|-------|---------------|
| **`threading`** | Keeps the app responsive during slow AI work |
| **`self.root.after()`** | Updates timer/status without freezing |
| **`update_idletasks()`** | Forces instant screen refresh |
| **`tempfile`** | Safely saves reports without cluttering your folders |
| **`class` and `self`** | Lets different parts of the app â€œtalkâ€ to each other (e.g., button tells progress bar to update) |

---

## ğŸ’¡ Tkinter tweaks!

Even if you donâ€™t write GUI code every day, you now understand:
- How the window is built
- How buttons trigger smart actions
- How the app stays smooth while doing heavy work
- How your local AI powers everythingâ€”privately and offline

And best of all: **you can tweak it!**  
Want a bigger text box? Change `height=10` â†’ `height=15`.  
Want to skip email? Comment out the `send_markdown_email` line.

Your desktop AI assistantâ€”fully under your control. ğŸ› ï¸âœ¨
